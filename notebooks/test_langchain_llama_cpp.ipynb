{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-experimental in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (0.0.55)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.13 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain-experimental) (0.1.13)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain-experimental) (0.1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (0.0.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.13->langchain-experimental) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-experimental) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-experimental) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.13->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.13->langchain-experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.13->langchain-experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.13->langchain-experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.13->langchain-experimental) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-experimental) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-experimental) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-experimental) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-experimental) (4.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.13->langchain-experimental) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.13->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.13->langchain-experimental) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.13->langchain-experimental) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.13->langchain-experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.13->langchain-experimental) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.13->langchain-experimental) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.13->langchain-experimental) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.13->langchain-experimental) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.13->langchain-experimental) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_experimental.chat_models import Llama2Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"BioMistral/BioMistral-7B-GGUF\"\n",
    "model_file = \"ggml-model-Q5_K_M.gguf\"\n",
    "local_path = \"../models/\" + model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = hf_hub_download(\n",
    "    repo_id = model_type,\n",
    "    filename = model_file,\n",
    "    local_dir=local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../models/BioMistral/BioMistral-7B-GGUF/ggml-model-Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = models\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = models\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4892.99 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.14 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     1.13 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token + ' ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '17', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'models'}\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "    model_path=local_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Llama2Chat(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthai=PromptTemplate(\n",
    "    input_variables=[\"Medical_history\"], template=\"\"\"\n",
    "You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user \n",
    "has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors. \n",
    "This is the medical history: {Medical_history}\n",
    "Provide recommendations such as diet and exercise plans, medication reminders, general wellness tips based on the user's inputs and established \n",
    "medical guidelines.\n",
    "Take note of the patient's allergy from the medical history. Ensure and maintain strict privacy and security measures to prtect users' sensitive \n",
    "information\n",
    "Ask questions only in queries that can not be fully undestood\"\"\")\n",
    "med_history=\"My name is Adah Augustine and I have diabetes\"\n",
    "prompt=healthai.format(Medical_history=med_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{human_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
    "# chain = ConversationChain(llm=llm, prompt=prompt_template, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2162.55 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    39 runs   (    0.09 ms per token, 11265.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4933.77 ms /    48 tokens (  102.79 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2811.20 ms /    39 runs   (   72.08 ms per token,    13.87 tokens per second)\n",
      "llama_print_timings:       total time =    7816.17 ms /    87 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' there! I am a 27 year old male. Over the last few months I have been experiencing a lot of stomach pains. I am also currently taking medication for my depression.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(human_input=\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = dict(\n",
    "        max_tokens=200,\n",
    "        top_p=0.2,\n",
    "        top_k=0.6,\n",
    "        temperature=0.1,\n",
    "        repeat_penalty=1.2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanmayvakare/.pyenv/versions/3.10.6/lib/python3.10/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'run_id': '8245e163-df2a-47c8-9ec5-b3298f445260', 'name': 'LLMChain', 'tags': [], 'metadata': {}, 'data': {'input': 'Hi'}}\n",
      "{'event': 'on_llm_start', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'input': {'prompts': ['System: You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors.\\nHuman: Hi']}}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' there'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' I'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' am'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' interested'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' in'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' knowing'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' about'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' my'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' health'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' risks'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '.'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' My'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' mum'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' had'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' breast'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' cancer'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' when'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' she'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' was'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' '}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '5'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '0'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' years'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' old'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '.'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' Since'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' then'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' I'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' have'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' also'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' noticed'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' that'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' I'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' have'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' a'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' few'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' white'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' patches'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' on'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' my'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' arm'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' and'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' also'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' suffer'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' from'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' head'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': 'aches'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' sometimes'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '.'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' Can'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' you'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' tell'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' me'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' more'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' about'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ' these'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': '?'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2500.13 ms\n",
      "llama_print_timings:      sample time =       5.15 ms /    58 runs   (    0.09 ms per token, 11253.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5244.09 ms /    48 tokens (  109.25 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4198.87 ms /    58 runs   (   72.39 ms per token,    13.81 tokens per second)\n",
      "llama_print_timings:       total time =    9547.97 ms /   106 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'chunk': ''}}\n",
      "{'event': 'on_llm_end', 'name': 'LlamaCpp', 'run_id': 'f9e677b7-abcb-4bd0-86eb-f79d2568d042', 'tags': [], 'metadata': {}, 'data': {'input': {'prompts': ['System: You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors.\\nHuman: Hi']}, 'output': {'generations': [[{'text': ' there I am interested in knowing about my health risks. My mum had breast cancer when she was 50 years old. Since then I have also noticed that I have a few white patches on my arm and also suffer from headaches sometimes. Can you tell me more about these?', 'generation_info': None, 'type': 'Generation'}]], 'llm_output': None, 'run': None}}}\n",
      "{'event': 'on_chain_stream', 'run_id': '8245e163-df2a-47c8-9ec5-b3298f445260', 'tags': [], 'metadata': {}, 'name': 'LLMChain', 'data': {'chunk': {'input': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content=' there I am interested in knowing about my health risks. My mum had breast cancer when she was 50 years old. Since then I have also noticed that I have a few white patches on my arm and also suffer from headaches sometimes. Can you tell me more about these?')], 'text': ' there I am interested in knowing about my health risks. My mum had breast cancer when she was 50 years old. Since then I have also noticed that I have a few white patches on my arm and also suffer from headaches sometimes. Can you tell me more about these?'}}}\n",
      "{'event': 'on_chain_end', 'name': 'LLMChain', 'run_id': '8245e163-df2a-47c8-9ec5-b3298f445260', 'tags': [], 'metadata': {}, 'data': {'output': {'input': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content=' there I am interested in knowing about my health risks. My mum had breast cancer when she was 50 years old. Since then I have also noticed that I have a few white patches on my arm and also suffer from headaches sometimes. Can you tell me more about these?')], 'text': ' there I am interested in knowing about my health risks. My mum had breast cancer when she was 50 years old. Since then I have also noticed that I have a few white patches on my arm and also suffer from headaches sometimes. Can you tell me more about these?'}}}\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "async for event in chain.astream_events(message, version=\"v1\", **generate_kwargs):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'run_id': '85127edb-afbd-4c4f-a058-0c3952ffd975', 'name': 'LLMChain', 'tags': [], 'metadata': {}, 'data': {'input': 'Hi'}}\n",
      "{'event': 'on_llm_start', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'input': {'prompts': ['System: You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors.\\nHuman: Hi\\nAI: ! I was wondering if you could recommend any exercises for my shoulder pain?\\nHuman: Hi']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': '!'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' I'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' have'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' been'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' experiencing'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' a'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' lot'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' of'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' pain'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' in'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' my'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' shoulder'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' and'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' it'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' is'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' really'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' starting'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' to'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' affect'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' daily'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' activities'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' such'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' as'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' br'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': 'ushing'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' my'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' hair'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' and'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' even'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' getting'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' dressed'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': '.'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' My'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' doctor'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' said'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' that'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' it'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' might'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' be'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' due'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' to'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' infl'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': 'amm'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': 'ation'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' in'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' the'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ' shoulder'}}\n",
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': '.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2500.13 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    49 runs   (    0.09 ms per token, 11303.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1677.42 ms /    23 tokens (   72.93 ms per token,    13.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3459.44 ms /    48 runs   (   72.07 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:       total time =    5224.21 ms /    71 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_llm_stream', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'chunk': ''}}\n",
      "{'event': 'on_llm_end', 'name': 'LlamaCpp', 'run_id': '84b95376-9c0f-4dff-856d-c22b8e1d62b8', 'tags': [], 'metadata': {}, 'data': {'input': {'prompts': ['System: You are a healthcare assistant chatbot that utilizes natural language processing to interact with user. The user has provided their Medical history which contains a summary of either past or current symptoms, medication and lifestyle factors.\\nHuman: Hi\\nAI: ! I was wondering if you could recommend any exercises for my shoulder pain?\\nHuman: Hi']}, 'output': {'generations': [[{'text': '! I have been experiencing a lot of pain in my shoulder and it is really starting to affect daily activities such as brushing my hair and even getting dressed. My doctor said that it might be due to inflammation in the shoulder.', 'generation_info': None, 'type': 'Generation'}]], 'llm_output': None, 'run': None}}}\n",
      "{'event': 'on_chain_stream', 'run_id': '85127edb-afbd-4c4f-a058-0c3952ffd975', 'tags': [], 'metadata': {}, 'name': 'LLMChain', 'data': {'chunk': {'human_input': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content='! I was wondering if you could recommend any exercises for my shoulder pain?'), HumanMessage(content='Hi'), AIMessage(content='! I have been experiencing a lot of pain in my shoulder and it is really starting to affect daily activities such as brushing my hair and even getting dressed. My doctor said that it might be due to inflammation in the shoulder.')], 'text': '! I have been experiencing a lot of pain in my shoulder and it is really starting to affect daily activities such as brushing my hair and even getting dressed. My doctor said that it might be due to inflammation in the shoulder.'}}}\n",
      "{'event': 'on_chain_end', 'name': 'LLMChain', 'run_id': '85127edb-afbd-4c4f-a058-0c3952ffd975', 'tags': [], 'metadata': {}, 'data': {'output': {'human_input': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content='! I was wondering if you could recommend any exercises for my shoulder pain?'), HumanMessage(content='Hi'), AIMessage(content='! I have been experiencing a lot of pain in my shoulder and it is really starting to affect daily activities such as brushing my hair and even getting dressed. My doctor said that it might be due to inflammation in the shoulder.')], 'text': '! I have been experiencing a lot of pain in my shoulder and it is really starting to affect daily activities such as brushing my hair and even getting dressed. My doctor said that it might be due to inflammation in the shoulder.'}}}\n"
     ]
    }
   ],
   "source": [
    "async for each in chain.astream_events(message, version=\"v1\", **generate_kwargs):\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2500.13 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    46 runs   (    0.09 ms per token, 11508.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3681.72 ms /    46 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    3756.89 ms /    47 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Hi', 'chat_history': [HumanMessage(content='Hi'), AIMessage(content='! I have recently noticed a lump in my neck. It’s small and only visible from the outside but it kind of hurts when I touch it. I am really scared and was wondering what could it be?')], 'text': '! I have recently noticed a lump in my neck. It’s small and only visible from the outside but it kind of hurts when I touch it. I am really scared and was wondering what could it be?'}\n"
     ]
    }
   ],
   "source": [
    "for each in chain.stream(message):\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
